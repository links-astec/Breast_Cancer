{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvch7eNKzXzDBulyYvzVNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/links-astec/Breast_Cancer/blob/main/breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLWh8La7fTrJ",
        "outputId": "c125f1d1-38f7-4d10-f706-839d66237a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to 'your_extraction_path': ['breast']\n",
            "Found 1400 images belonging to 2 classes.\n",
            "Found 80 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "43/43 [==============================] - 103s 2s/step - loss: 0.7318 - accuracy: 0.5592 - val_loss: 0.6554 - val_accuracy: 0.5625\n",
            "Epoch 2/10\n",
            "43/43 [==============================] - 86s 2s/step - loss: 0.6209 - accuracy: 0.6572 - val_loss: 0.7243 - val_accuracy: 0.5625\n",
            "Epoch 3/10\n",
            "43/43 [==============================] - 88s 2s/step - loss: 0.5721 - accuracy: 0.6930 - val_loss: 1.0563 - val_accuracy: 0.4219\n",
            "Epoch 4/10\n",
            "43/43 [==============================] - 90s 2s/step - loss: 0.5147 - accuracy: 0.7478 - val_loss: 1.0596 - val_accuracy: 0.4531\n",
            "Epoch 5/10\n",
            "43/43 [==============================] - 85s 2s/step - loss: 0.4886 - accuracy: 0.7727 - val_loss: 1.4571 - val_accuracy: 0.4219\n",
            "Epoch 6/10\n",
            "43/43 [==============================] - 90s 2s/step - loss: 0.4027 - accuracy: 0.8129 - val_loss: 1.4199 - val_accuracy: 0.4531\n",
            "Epoch 7/10\n",
            "43/43 [==============================] - 87s 2s/step - loss: 0.3838 - accuracy: 0.8238 - val_loss: 1.4190 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "43/43 [==============================] - 86s 2s/step - loss: 0.3399 - accuracy: 0.8428 - val_loss: 1.7109 - val_accuracy: 0.4062\n",
            "Epoch 9/10\n",
            "43/43 [==============================] - 88s 2s/step - loss: 0.2630 - accuracy: 0.8882 - val_loss: 2.8074 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "43/43 [==============================] - 87s 2s/step - loss: 0.2716 - accuracy: 0.8852 - val_loss: 1.9593 - val_accuracy: 0.3594\n",
            "Accuracy: 88.52%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Replace 'breast.rar' with the actual name of your RAR file\n",
        "rar_file_path = 'breast.rar'\n",
        "\n",
        "# Replace 'your_extraction_path' with the desired extraction path\n",
        "extraction_path = 'your_extraction_path'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "# Use the unrar command to extract the contents\n",
        "os.system(f\"unrar x {rar_file_path} {extraction_path}\")\n",
        "\n",
        "# List the files in the extraction directory\n",
        "extracted_files = os.listdir(extraction_path)\n",
        "print(f\"Files extracted to '{extraction_path}': {extracted_files}\")\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Set the path to your train and validation directories\n",
        "train_dir = '/content/your_extraction_path/breast/train'  # Replace with the path to your train directory\n",
        "validation_dir = '/content/your_extraction_path/breast/validation'  # Replace with the path to your validation directory\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for the training dataset\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Rescale the validation dataset\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load and prepare the training dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Load and prepare the validation dataset\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(history.history['accuracy'][-1] * 100))\n",
        "\n",
        "# Save the trained model\n",
        "model.save('breast_cancer_cnn.keras')\n"
      ]
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "rar_file_path = 'breastss.rar'\n",
        "\n",
        "extraction_path = 'your_extraction'\n",
        "\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "# Use the unrar command to extract the contents\n",
        "os.system(f\"unrar x {rar_file_path} {extraction_path}\")\n",
        "\n",
        "# List the files in the extraction directory\n",
        "extracted_files = os.listdir(extraction_path)\n",
        "print(f\"Files extracted to '{extraction_path}': {extracted_files}\")\n",
        "\n",
        "# Set the path to your train and validation directories\n",
        "train_dir = '/content/your_extraction/breasts/train'  # Replace with the path to your train directory\n",
        "validation_dir = '/content/your_extraction/breasts/validation'  # Replace with the path to your validation directory\n",
        "test_dir = '/content/your_extraction/breasts/test'  # Replace with the path to your test directory\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for the training dataset\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2\n",
        ")\n",
        "\n",
        "# Rescale the validation dataset\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load and prepare the training dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory= '/content/your_extraction/breastss/train',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Load and prepare the validation dataset\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    directory= '/content/your_extraction/breastss/validation',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Load and prepare the test dataset\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory= '/content/your_extraction/breastss/test',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(lr=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = model.evaluate(test_generator)[1]\n",
        "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
        "\n",
        "# Save the trained model\n",
        "model.save('breast_cancer.keras')\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "AlQ6qNlS5O_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2598980f-6b25-4134-f1ea-ef46fcfb965f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to 'your_extraction': ['breastss']\n",
            "Found 1400 images belonging to 2 classes.\n",
            "Found 80 images belonging to 2 classes.\n",
            "Found 1225 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "43/43 [==============================] - 107s 2s/step - loss: 14.0930 - accuracy: 0.5468 - val_loss: 8.9420 - val_accuracy: 0.5781\n",
            "Epoch 2/10\n",
            "43/43 [==============================] - 107s 2s/step - loss: 7.2523 - accuracy: 0.5487 - val_loss: 8.5184 - val_accuracy: 0.4531\n",
            "Epoch 3/10\n",
            "43/43 [==============================] - 95s 2s/step - loss: 4.8249 - accuracy: 0.5819 - val_loss: 5.1488 - val_accuracy: 0.5312\n",
            "Epoch 4/10\n",
            "43/43 [==============================] - 92s 2s/step - loss: 3.4988 - accuracy: 0.6199 - val_loss: 3.4944 - val_accuracy: 0.4844\n",
            "Epoch 5/10\n",
            "43/43 [==============================] - 97s 2s/step - loss: 2.7513 - accuracy: 0.5789 - val_loss: 2.6016 - val_accuracy: 0.4844\n",
            "Epoch 6/10\n",
            "43/43 [==============================] - 95s 2s/step - loss: 2.2440 - accuracy: 0.5811 - val_loss: 2.6548 - val_accuracy: 0.1094\n",
            "Epoch 7/10\n",
            "43/43 [==============================] - 92s 2s/step - loss: 1.9179 - accuracy: 0.5629 - val_loss: 1.9664 - val_accuracy: 0.4688\n",
            "Epoch 8/10\n",
            " 1/43 [..............................] - ETA: 1:33 - loss: 1.7511 - accuracy: 0.5938"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Replace 'breast.rar' with the actual name of your RAR file\n",
        "rar_file_path = 'breastss.rar'\n",
        "\n",
        "# Replace 'your_extraction_path' with the desired extraction path\n",
        "extraction_path = 'your_extraction'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "# Use the unrar command to extract the contents\n",
        "os.system(f\"unrar x {rar_file_path} {extraction_path}\")\n",
        "\n",
        "# List the files in the extraction directory\n",
        "extracted_files = os.listdir(extraction_path)\n",
        "print(f\"Files extracted to '{extraction_path}': {extracted_files}\")\n",
        "\n",
        "# Set the path to your train and validation directories\n",
        "train_dir = '/content/your_extraction_path/breastss/train'  # Replace with the path to your train directory\n",
        "validation_dir = '/content/your_extraction_path/breastss/validation'  # Replace with the path to your validation directory\n",
        "test_dir = '/content/your_extraction_path/breastss/test'  # Replace with the path to your test directory\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (540, 250)\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for the training dataset\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2\n",
        ")\n",
        "\n",
        "# Rescale the validation dataset\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load and prepare the training dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory= '/content/your_extraction/breastss/train',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Load and prepare the validation dataset\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    directory= '/content/your_extraction/breastss/validation',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Load and prepare the test dataset\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory='/content/your_extraction/breastss/test',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Update the input shape to match your image size\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(540, 250, 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(lr=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = model.evaluate(test_generator)[1]\n",
        "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
        "\n",
        "# Save the trained model\n",
        "model.save('breast.keras')\n"
      ],
      "metadata": {
        "id": "R6AASneQn7rg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}